{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Stocks Data Analysis and Visualization in Python"
      ],
      "metadata": {
        "id": "GdijhR3S4Drj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yfinance\n",
        "import yfinance as yf\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "from copy import copy\n",
        "import plotly.express as px\n",
        "import plotly.figure_factory as ff\n",
        "import plotly.graph_objects as go"
      ],
      "metadata": {
        "id": "-D6xJ4Cq3WYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stocks_df = pd.read_csv('stock.csv')\n",
        "print(stocks_df)\n",
        "\n",
        "# Number of stocks\n",
        "print('Total Number of stocks: {}'.format(len(stocks_df.columns[1:])))\n",
        "\n",
        "# Sort the stock data by data\n",
        "stock = stocks_df.sort_values(by = ['Date'])\n",
        "print(stock)\n",
        "\n",
        "# Name of stocks\n",
        "print('Stocks under consideration are:')\n",
        "for i in stocks_df.columns[1:]:\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "Uyg2nBxU3WWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Average return os SP500\n",
        "# Stock/index has the minimum dispertion from the mean in dollar value\n",
        "# The maximum price for AMZN stock over the specified time period\n",
        "print(stocks_df.mean(),\n",
        "      stocks_df.std(),\n",
        "      stocks_df.describe())"
      ],
      "metadata": {
        "id": "ho8uy4Ys3WTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking data for nulls values\n",
        "print(stocks_df.isnull().sum())\n",
        "\n",
        "# Getting dataframe info\n",
        "print(stocks_df.info())\n",
        "\n",
        "# Ploting data \n",
        "def show_plot(df, fig_title):\n",
        "  df.plot(x = 'Date', figsize = (15, 7), linewidth = 3, title = fig_title)\n",
        "  plt.grid()\n",
        "  plt.show()\n",
        "\n",
        "show_plot(stocks_df, 'Raw Stock Prices (Without Normalization)')\n",
        "\n",
        "def normalize(df):\n",
        "  x = df.copy()\n",
        "  for i in x.columns[1:]:\n",
        "    x[i] = x[i]/x[i][0]\n",
        "  return x\n",
        "\n",
        "normalize(stocks_df)\n",
        "show_plot(normalize(stocks_df), 'Normalized Stock Prices')"
      ],
      "metadata": {
        "id": "tSA1xgUV3WR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def interactive_plot(df, title):\n",
        "  fig = px.line(title = title)\n",
        "  for i in df.columns[1:]:\n",
        "    fig.add_scatter(x = df['Date'] , y = df[i], name = i)\n",
        "  fig.show()\n",
        "\n",
        "interactive_plot(stocks_df, 'Prices')\n",
        "interactive_plot(normalize(stocks_df), 'Normalize Prices')"
      ],
      "metadata": {
        "id": "r8acaF-x3WPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = stocks_df['sp500']\n",
        "print(df)\n",
        "\n",
        "df_daily_return = df.copy()\n",
        "for i in range(1, len(df)):\n",
        "  df_daily_return[i] = ((df[i] - df[i-1]) / df[i-1]) * 100\n",
        "\n",
        "df_daily_return[0] = 0\n",
        "print(df_daily_return)"
      ],
      "metadata": {
        "id": "9CYRg-sD3WLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to calculate stock daily returns (for all stocks)\n",
        "def daily_return(df):\n",
        "  df_daily_return = df.copy()\n",
        "\n",
        "  for i in df.columns[1:]:\n",
        "    for j in range(1, len(df)):\n",
        "      df_daily_return[i][j] = ((df[i][j] - df[i][j-1])/df[i][j-1]) * 100\n",
        "    df_daily_return[i][0] = 0\n",
        "\n",
        "  return df_daily_return\n",
        "\n",
        "stocks_daily_return = daily_return(stocks_df)\n",
        "print(stocks_daily_return,\n",
        "      show_plot(stocks_daily_return, 'Stocks Daily Returns'),\n",
        "      interactive_plot(stocks_daily_return, 'Stocks Daily Return'))"
      ],
      "metadata": {
        "id": "i8jeDfd43WJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Daily Return Correlation\n",
        "cm = stocks_daily_return.drop(columns = ['Date']).corr()\n",
        "plt.figure(figsize = (10,10))\n",
        "sns.heatmap(cm, annot = True)"
      ],
      "metadata": {
        "id": "u4itUN0l3WGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogram of daily return\n",
        "# Stock returns are normally distributed with zero mean\n",
        "# Notice how tesla Standard deviation is high indicating a more volatile stock\n",
        "stocks_daily_return.hist(figsize = (10,10), bins = 40)\n",
        "\n",
        "df_hist = stocks_daily_return.copy()\n",
        "df_hist = df_hist.drop(columns = ['Date'])\n",
        "data = []\n",
        "\n",
        "for i in df_hist.columns:\n",
        "  data.append(stocks_daily_return[i].values)\n",
        "\n",
        "print(data)\n",
        "\n",
        "fig = ff.create_distplot(data, df_hist.columns)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "h2WU6dAc3WEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Asset Allocation and Statistical Data Analysis"
      ],
      "metadata": {
        "id": "n9c4gyCQGdTd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Ogb40J23QGW"
      },
      "outputs": [],
      "source": [
        "stocks_df = stocks_df.sort_values(by = ['Date'])\n",
        "print(stocks_df)\n",
        "\n",
        "def normalize(df):\n",
        "  x = df.copy()\n",
        "  for i in x.columns[1:]:\n",
        "    x[i] = x[i][0] / x[i][0]\n",
        "  return x\n",
        "\n",
        "def interactive_plot(df, title):\n",
        "  fig = px.line(title = title)\n",
        "  for i in df.columns[1:]:\n",
        "    fig.add_scatter(x = df['Date'], y = df[i], name = i)\n",
        "  fig.show()\n",
        "\n",
        "# plot raw data\n",
        "print(interactive_plot(stocks_df, 'Prices'))\n",
        "print(interactive_plot(normalize(stocks_df), 'Normalized Prices'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create random portfolio weights\n",
        "np.random.seed(101)\n",
        "weights = np.array(np.random.random(9))\n",
        "weights = weights/np.sum(weights)\n",
        "print(weights)\n",
        "\n",
        "df_portfolio = normalize(stocks_df)\n",
        "print(df_portfolio)\n",
        "print(df_portfolio.columns[1:])\n",
        "\n",
        "for counter, stock in enumerate(df_portfolio.columns[1:]):\n",
        "  df_portfolio[stock] = df_portfolio[stock] * weights[counter]\n",
        "  df_portfolio[stock] = df_portfolio[stock] * 1000000\n",
        "\n",
        "df_portfolio\n",
        "\n",
        "df_portfolio['portfolio daily worth in $'] = df_portfolio[df_portfolio != 'Date'].sum(axis = 1)\n",
        "print(df_portfolio)\n",
        "\n",
        "df_portfolio['portfolio daily % return'] = 0.0000\n",
        "\n",
        "for i in range(1, len(stocks_df)):\n",
        "  df_portfolio['portfolio daily % return'][i] = ((df_portfolio['portfolio daily worth in $'][i]) - (df_portfolio['portfolio daily worth in $'][i-1]))\n",
        "\n",
        "print(df_portfolio)"
      ],
      "metadata": {
        "id": "VqeCDMMsv68d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def portfolio_allocation(df, weights):\n",
        "  df_portfolio = df.copy()\n",
        "  df_portfolio = normalize(df_portfolio)\n",
        "\n",
        "  for counter, stock in enumerate(df_portfolio.columns[1:]):\n",
        "    df_portfolio[stock] = df_portfolio[stock] * weights[counter]\n",
        "    df_portfolio[stock] = df_portfolio[stock] * 1000000\n",
        "\n",
        "  df_portfolio['portfolio daily worth in $'] = df_portfolio[df_portfolio != 'Date'].sum(axis = 1)\n",
        "  df_portfolio['portfolio daily % return'] = 0.0000\n",
        "\n",
        "  for i in range(1, len(stocks_df)):\n",
        "    df_portfolio['portfolio daily % return'][i] = ((df_portfolio['portfolio daily worth in $'][i]) - (df_portfolio['portfolio daily worth in $'][i-1]))\n",
        "\n",
        "  df_portfolio['portfolio daily % return'][0] = 0\n",
        "  return df_portfolio\n",
        "\n",
        "df_portfolio = portfolio_allocation(stocks_df, weights)\n",
        "print(df_portfolio)"
      ],
      "metadata": {
        "id": "IOET3DQxVE-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.line(x = df_portfolio['Date'] ,y = df_portfolio['portfolio daily % return'], title='Portfolio Daily % Return')\n",
        "fig.show()\n",
        "\n",
        "interactive_plot(df_portfolio.drop(['portfolio daily worth in $', 'portfolio daily % return'], axis = 1), 'Portfolio Individual stocks worth in $ overtime')\n",
        "\n",
        "fig = px.histogram(df_portfolio, x = 'portfolio daily % return')\n",
        "fig.show()\n",
        "\n",
        "fig = px.line(x = df_portfolio['Date'], y = df_portfolio['portfolio daily worth in $'], title = 'Portfolio Overall Value in $')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "y3gxfRr8b5mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Captial Asset Pricing Model(CAPM)"
      ],
      "metadata": {
        "id": "p6Im0-M8mKsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function calculate daily returns\n",
        "def daily_returns(df):\n",
        "  df_daily_return = df.copy()\n",
        "  for i in df.columns[1:]:\n",
        "    for j in range(1, len(df)):\n",
        "      df_daily_return[i][j] = ((df[i][j] - df[i][j-1]) / df[i][j-1]) * 100\n",
        "    df_daily_return[i][0] = 0\n",
        "  return df_daily_return\n",
        "\n",
        "stocks_daily_return = daily_returns(stocks_df)\n",
        "print(stocks_daily_return)\n",
        "\n",
        "# Calculate Beta for a Single Stock\n",
        "stocks_daily_return['AAPL']\n",
        "stocks_daily_return['sp500']\n",
        "stocks_daily_return.plot(kind = 'scatter', x = 'sp500', y = 'AAPL')\n",
        "\n",
        "beta, alpha = np.polyfit(stocks_daily_return['sp500'], stocks_daily_return['AAPL'], 1)\n",
        "print('Beta for {} stock is {} and alpha is {}'.format('AAPL', beta, alpha))\n",
        "\n",
        "plt.plot(stocks_daily_return['sp500'], beta * stocks_daily_return['sp500'] + alpha, '-', color = 'r')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mCGan8VEFJcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict Stocks Future Prices Using Machine and Deep Learning"
      ],
      "metadata": {
        "id": "ShlXveXeGlqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from tensorflow import keras\n",
        "\n",
        "# Stock price\n",
        "stocks_price = pd.read_csv('stock.csv')\n",
        "print(stocks_price)\n",
        "\n",
        "# Stock volume price\n",
        "stock_vol = pd.read_csv('stock_volume.csv')\n",
        "print(stock_vol)"
      ],
      "metadata": {
        "id": "JapL8TPAFJZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to noralize stock prices based on initial price\n",
        "def normalize(df):\n",
        "  x = df.copy()\n",
        "  for i in x.columns[1:]:\n",
        "    x[i] = x[i]/x[i][0]\n",
        "  return x\n",
        "\n",
        "# Function to plot interactive plots using Ploty Express\n",
        "def interactive_plot(df, title):\n",
        "  fig = px.line(title = title)\n",
        "  for i in df.columns[1:]:\n",
        "    fig.add_scatter(x = df['Date'], y = df[i], name = i)\n",
        "  fig.show()\n",
        "\n",
        "interactive_plot(stocks_price, 'Stock Prices')\n",
        "\n",
        "# Ploting the volume dataset for all stocks\n",
        "# Plot the normalized stock prices and volume dataset\n",
        "interactive_plot(stock_vol, 'Stock Volume')\n",
        "interactive_plot(normalize(stocks_price, 'Norm Stock Volume'))"
      ],
      "metadata": {
        "id": "btwOeOS0oFYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# Function to concretenate the data, stock price and volume in one dataframe\n",
        "def individual_stock(price_df, vol_df, name):\n",
        "  return pd.DataFrame({'Date': price_df['Date'], ['Close']: price_df[name],'Volume': vol_df[name] })\n",
        "\n",
        "# Function to return the input/output (target) data for AI/ML Model\n",
        "def trading_window(data):\n",
        "  n = 1\n",
        "  data['Target'] = data[['Close']].shift(-n)\n",
        "  return data\n",
        "\n",
        "price_vol = individual_stock(stocks_price, stock_vol, 'AAPL')\n",
        "print(price_vol)\n",
        "\n",
        "price_target = trading_window(price_vol)\n",
        "print(price_target)\n",
        "\n",
        "price_target = price_target[1:]\n",
        "print(price_target)\n",
        "\n",
        "sc = MinMaxScaler(feature_range = (0,1))\n",
        "price_target_sd = sc.fit_transform(price_target.drop(columns = ['Date']))\n",
        "print(price_target_sd)\n",
        "\n",
        "# Creating a feature and target\n",
        "x = price_target_sd[:, :2]\n",
        "y = price_target_sd[:, 2:]\n",
        "\n",
        "# Define a data plotting function\n",
        "def show_plot(data, title):\n",
        "  plt.figure(figsize = (13, 5))\n",
        "  plt.plot(data, linewidth = 3)\n",
        "  plt.title(title)\n",
        "  plt.grid()"
      ],
      "metadata": {
        "id": "w9EJMKek3BAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "# Create and train the ridge linear regression model\n",
        "split = int(0.65 * len(x))\n",
        "xTest = x[split:]\n",
        "yTest = y[split:]\n",
        "xTrain = x[:split]\n",
        "yTrain = y[:split]\n",
        "\n",
        "reg_model = Ridge(alpha = 2)\n",
        "reg_model.fit(xTrain, yTrain)\n",
        "\n",
        "# test the model and calculate its accuracy\n",
        "lr_acc = reg_model.score(xTest, yTest)\n",
        "print('Rdige Regression Score:', lr_acc)\n",
        "\n",
        "# Make Prediction\n",
        "pred_price = reg_model.predict(x)\n",
        "print(pred_price)\n",
        "\n",
        "# Append the predicted values into a list\n",
        "predicted = []\n",
        "for i in pred_price:\n",
        "  predicted.append(i[0])\n",
        "len(predicted)\n",
        "\n",
        "# Append the close values into a list\n",
        "close = []\n",
        "for i in price_target_sd:\n",
        "  close.append(i[0])\n",
        "\n",
        "# Create a datframe on the dates in the individual stock data\n",
        "df_pred = price_target[['Date']]\n",
        "print(df_pred)\n",
        "\n",
        "# Add the create values to the dataframe\n",
        "df_pred['Close'] = close\n",
        "print(df_pred)\n",
        "\n",
        "# Add the predicted values to the dataframe \n",
        "df_pred['Prediction'] = predicted\n",
        "print(df_pred)\n",
        " # Plot the results\n",
        "interactive_plot(df_pred, 'Original vs Predictions')"
      ],
      "metadata": {
        "id": "jnmou0agWDDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# Train an LSTM Time Series Model\n",
        "price_vdf = individual_stock(stocks_price, stock_vol, 'sp500')\n",
        "print(price_vdf)\n",
        "\n",
        "train_data = price_vdf.iloc[:, :3].values\n",
        "print(train_data)\n",
        "\n",
        "sc = MinMaxScaler(feature_range = (0,1))\n",
        "training_set = sc.fit_tranform(train_data)\n",
        "\n",
        "# Creating the training and testing data\n",
        "x = []\n",
        "y = []\n",
        "for i in range(1, len(price_vdf)):\n",
        "  x.append(training_set[i:1:i, 0])\n",
        "  y.append(training_set[i:0])\n",
        "\n",
        "# Convert the data into array format\n",
        "x = np.asarray(x)\n",
        "y = np.asarray(y)\n",
        "\n",
        "# Split the data\n",
        "split = int(0.7 * len(x))\n",
        "xTest = x[split:]\n",
        "yTest = y[split:]\n",
        "xTrain = x[:split]\n",
        "yTrain = y[:split]\n",
        "\n",
        "# Reshape the 1D arrays to feed in the model\n",
        "xTrain = np.reshape(xTrain, (xTrain.shape[0], xTrain.shape[1], 1))\n",
        "xTest = np.reshape(xTest, (xTest.shape[0], xTest.shape[1], 1))\n",
        "print(xTrain.shape, xTest.shape)\n",
        "\n",
        "# Create and train the model\n",
        "input = keras.layers.Input(shape = xTrain.shape[1], xTrain.shape[2])\n",
        "x = keras.layers.LSTM(150, return_seguences = True)(input)\n",
        "x = keras.layers.LSTM(150, return_seguences = True)(input)\n",
        "x = keras.layers.LSTM(150, return_seguences = True)(x)\n",
        "\n",
        "output = keras.layers.Dense(1, activation = 'linear')(x)\n",
        "model = keras.Model(inputs = input , outputs = output)\n",
        "model.complir(optimizer = 'adam', loss = 'mse')\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(xTrain, yTrain, epochs = 2, batch_size = 32, validation_split = 0.2)\n",
        "\n",
        "# Make prediction and append to a list\n",
        "pred = model.predict(x)\n",
        "test_pred = []\n",
        "for i in pred:\n",
        "  test_pred.append(i[0])\n",
        "\n",
        "df_pred = price_vdf[1:]['Date', 'Close']\n",
        "print(df_pred)\n",
        "\n",
        "df_pred['predictions'] = test_pred\n",
        "print(df_pred)\n",
        "\n",
        "for i in pred:\n",
        "  test_pred.append(i[0][0])\n",
        "\n",
        "print(test_pred)\n",
        "\n",
        "close = []\n",
        "for i in training_set:\n",
        "  close.append(i[0])\n",
        "\n",
        "print(close)\n",
        "\n",
        "df_pred['Close'] = close[1:]\n",
        "print(df_pred)\n",
        "\n",
        "interactive_plot(df_pred, 'Original Price vs LSTM Predictions')"
      ],
      "metadata": {
        "id": "mc4LQvOZHyEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perfom Bank Market Segmentation Using Unsupervised Machine Learning Techniques"
      ],
      "metadata": {
        "id": "kln9MReAGtck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "creditcard = pd.read_csv('/content/4.+Marketing_data.csv')\n",
        "print(creditcard, creditcard.info(), creditcard.describe())\n",
        "\n",
        "# Purchases of $40761\n",
        "creditcard[creditcard['ONEOFF_PURCHASES'] == 40761.250000]\n",
        "\n",
        "# Never paid credit card in full\n",
        "creditcard[creditcard['CASH_ADVANCE'] == 47137.211760000006]"
      ],
      "metadata": {
        "id": "wShFdnLDFJWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding any missing data\n",
        "sns.heatmap(creditcard.isnull(), yticklabels = False, char = False, cmap = 'Blues')\n",
        "creditcard.isnull().sum()\n",
        "\n",
        "creditcard.loc[(creditcard['MINIMUM_PAYMENTS'].isnull() == True), 'MINIMUM_PAYMENTS'] = creditcard['MINIMUM_PAYMENTS'].mean()\n",
        "creditcard.isnull().sum()\n",
        "\n",
        "# Fill up missing elements with mean of the credit limit\n",
        "creditcard.loc[(creditcard['CREDIT_LIMIT'].isnull() == True), 'CREDIT_LIMIT'] = creditcard['CREDIT_LIMIT'].mean()\n",
        "creditcard.isnull().sum()\n",
        "\n",
        "# Find a deplicated entries in the data\n",
        "creditcard.duplicated().sum()\n",
        "\n",
        "# Dropping customer IDs\n",
        "creditcard.drop('CUST_ID', axis = 1, inplace = True)\n",
        "creditcard.head()\n",
        "\n",
        "n = len(creditcard.columns)\n",
        "print(n)\n",
        "\n",
        "plt.figure(figsize = (10,50))\n",
        "for i in range(len(creditcard.columns)):\n",
        "  plt.subplot(17, 1, i+1)\n",
        "  sns.distplot(creditcard[creditcard.columns[i]], kde_kws ={'color':'b', '1w':3, 'label': 'KDE', hist_kws = {'color': 'g'}})\n",
        "  plt.title(creditcard.columns[i])\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# Trend between 'PUCHASES' and 'CREDIT_LIMIT' & 'PAYMENTS'\n",
        "correlations = creditcard.corr()\n",
        "\n",
        "f, ax = plt.subplot(figsize = (20,20))\n",
        "sns.heatmap(correlations, annot = True)"
      ],
      "metadata": {
        "id": "-jBvsxaz7sar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler, normalize\n",
        "# Find the optimal number of clusters using elbow method\n",
        "scaler = StandardScaler()\n",
        "creditcard_sd = scaler.fit_transform(creditcard)\n",
        "print(creditcard_sd.shape)\n",
        "\n",
        "score_1 = []\n",
        "range_values = range(1,20)\n",
        "\n",
        "for i in range_values:\n",
        "  kmeans = KMeans(n_cluster = i)\n",
        "  kmeans.fit(creditcard_sd)\n",
        "  score_1.append(kmeans.inerta_)\n",
        "\n",
        "plt.plot(score_1, 'bx-')\n",
        "plt.title(\"Finding the right number of clusters\")\n",
        "plt.xlabel('Clusters')\n",
        "plt.ylabel('Scores WCSS')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TuEeaiPaBzxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying K-Means Method\n",
        "kmeans = KMeans(8)\n",
        "kmeans.fit(creditcard_sd)\n",
        "labels = kmeans.labels_\n",
        "\n",
        "print(labels)\n",
        "\n",
        "kmeans.cluster_centers_.shape\n",
        "cluster_centers = pd.DataFrame(data = kmeans.cluster_centers_, columns = [creditcard.columns])\n",
        "\n",
        "# concatenate the clusters labels to our original dataframe\n",
        "creditcard_clust = pd.concat([creditcard, pd.DataFrame({'cluster':labels})], axis = 1)\n",
        "creditcard_clust.head()\n",
        "\n",
        "for i in creditcard.columns:\n",
        "  plt.figure(figsize = (35,5))\n",
        "  for j in range(8):\n",
        "    plt.subplot(1,8,j+1)\n",
        "    cluster = creditcard_clust[creditcard['cluster'] == j]\n",
        "    cluster[i].hist(bins = 20)\n",
        "    plt.title('{} \\nCluster {}'.format(i, j))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "480U_oYPBztf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "# Obtain the principal Componets\n",
        "pca = PCA(n_componets = 2)\n",
        "princ_comp = pca.fit_transform(creditcard_sd)\n",
        "print(princ_comp)\n",
        "\n",
        "# Create a dataframe with the two componets\n",
        "pca_df = pd.DataFrame(data = princ_comp, columns = ['pca1', 'pca2'])\n",
        "pca_df.head()\n",
        "\n",
        "# Concatenate the clusters labels to the dataframe \n",
        "pca_df = pd.concat([pca_df, pd.DataFrame({'cluster': labels})], axis = 1)\n",
        "pca_df.head()\n",
        "\n",
        "plt.figure(figsize = (10,10))\n",
        "ax = sns.scatterplot(x = 'pcal', y = 'pca2', hue = 'cluster', data = pca_df, palette = ['red', 'green', 'blue', 'gray', 'pink', 'yellow', 'black'])"
      ],
      "metadata": {
        "id": "VO6OuI6CLbC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Autoencoders (Perform Dimensionlity Reduction using Autoencoders)\n",
        "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "input_df = Input(shape = (17, ))\n",
        "x = Dense (7, activation = 'relu')(input_df)\n",
        "x = Dense(500, activation = 'relu', kernal_inititalizer = 'glorot_uniform')(x)\n",
        "x = Dense(500, activation = 'relu', kernal_inititalizer = 'glorot_uniform')(x)\n",
        "x = Dense(2000, activation = 'relu', kernal_inititalizer = 'glorot_uniform')(x)\n",
        "\n",
        "encoded = Dense (10, activation = 'relu', kernal_inititalizer = 'glorot_uniform')(x)\n",
        "\n",
        "x = Dense(2000, activation = 'relu', kernal_inititalizer = 'glorot_uniform')(encoded)\n",
        "x = Dense(2000, activation = 'relu', kernal_inititalizer = 'glorot_uniform')(x)\n",
        "\n",
        "decoded = x = Dense(17, kernal_inititalizer = 'glorot_uniform')(x)\n",
        "\n",
        "# Autocoder / Encoder\n",
        "autoencoder = Model(input_df, decoded)\n",
        "encoder = Model(input_df, encoded)\n",
        "\n",
        "autoencoder.complie(optimizer = 'adam', loss = 'mean_square_error')\n",
        "creditcard_sd.shape\n",
        "\n",
        "autoencoder.fit(creditcard_sd, creditcard_sd, batch_size = 128, epochs = 25, verbose = 1)\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "id": "tmTtTXqXLbAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = encoder.predict(ctreditcard_sd)\n",
        "print(pred, pred.shape)\n",
        "\n",
        "# optimal Number of clusters\n",
        "# kmeans\n",
        "# PCA\n",
        "score_2 = []\n",
        "range_values = range(1,20)\n",
        "\n",
        "for i in range_values:\n",
        "  kmeans = KMeans(n_cluster = i)\n",
        "  kmeans.fit(pred)\n",
        "  score_2.append(kmeans.inerta_)\n",
        "\n",
        "plt.plot(score_2, 'bx-')\n",
        "plt.title(\"Finding the right number of clusters\")\n",
        "plt.xlabel('Clusters')\n",
        "plt.ylabel('Scores')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(score_1, 'bx-', color = 'r')\n",
        "plt.plot(score_2, 'bx-', color = 'g')\n",
        "\n",
        "kmeans = KMeans(4)\n",
        "kmeans.fit(pred)\n",
        "labels = kmeans.labels_\n",
        "\n",
        "df_cluster_dr = pd.concat([creditcard, pd.DataFrame({'cluster':labels})], axis = 1)\n",
        "df_cluster_dr.head()\n",
        "\n",
        "pca = PCA(n_componets = 2)\n",
        "prin_comp = pca.fit_transform(pred)\n",
        "pca_df = pd.DataFrame(data = prin_comp, columns = ['pca1', 'pca2'])\n",
        "pca_df = pd.concat([pca_df, pd.DataFrame({'cluster':labels,}], axis = 1)\n",
        "pca_df.head()\n",
        "\n",
        "plt.figure(figsize = (10,10))\n",
        "ax = sns.scatterplot(x = 'pca1', y = 'pca2', hue = 'cluster', data = pca_df, palette = ['red', 'green', 'blue', 'gray', 'pink', 'yellow', 'black'])"
      ],
      "metadata": {
        "id": "qx4SK6W8La9B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}